<!--
    This project page is mainly referenced from https://imagen.research.google/editor/.
    Thanks to the authors for their great work.
-->

<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" />
    <link rel="stylesheet" type="text/css" href="styles.css" />
    <title>ByteEdit</title>
  </head>
  <body>
    <div class="block"></div>
    <div class="wrapper">
      <div class="block center">
        <p class="title">ByteEdit</p>
        <p class="subtitle">Boost, Comply and Accelerate Generative Image Editing</p>
        <p class="author">
            <a href="https://scholar.google.com/citations?user=C_6JH-IAAAAJ&hl=zh-CN&oi=ao">Yuxi Ren</a><sup>*</sup>,
            <a href="https://scholar.google.com/citations?user=MxvLqLcAAAAJ&hl=zh-CN&oi=ao">Jie Wu</a><sup>*†</sup>,
            <a href="https://scholar.google.com/citations?user=7YqvlBoAAAAJ&hl=zh-CN&oi=ao">Yanzuo Lu</a><sup>*</sup>,
            <a href="https://scholar.google.com/citations?user=FunSYJUAAAAJ&hl=zh-CN&oi=ao">Huafeng Kuang</a>,
            <a href="https://scholar.google.com/citations?user=JP14UGgAAAAJ&hl=zh-CN&oi=ao">Xin Xia</a>,
            Xionghui Wang,
            Qianqian Wang,
            Yixing Zhu,
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=Z-0EqtgAAAAJ">Pan Xie</a>,
            Shiyin Wang,
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=CVkM9TQAAAAJ">Xuefeng Xiao</a>,
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=NfFTKfYAAAAJ">Yitong Wang</a>,
            Min Zheng,
            Lean Fu
        </p>
        <c>ByteDance Inc.&emsp;<i><sup>*</sup>Equal Contribution&emsp;<sup>†</sup>Project Lead</i></c>
        <div class="button-container">
          <a href="">
            <div class="button">
              <a href="https://arxiv.org/abs/2404.04860">Research Paper</a>
            </div>
          </a>
        </div>
      </div>

      <div class="block">
        <p class="section-title" style="margin-top: 30px;">Inpainting Demo</p>
        <!-- <div class="gif-viewer">
            <button id="left-button-in">&lt;</button>
            <img id="gif-display-in" src="gif/inpainting/inpainting-1.gif" />
            <button id="right-button-in">&gt;</button>
        </div> -->
        <img class="image" width="100%" src="inpainting.gif">
        <!-- <script src="script.js"></script> -->
      </div>
      <div class="block">
        <p class="section-title" style="margin-top: 30px;">Outpainting Demo</p>
        <!-- <div class="gif-viewer">
            <button id="left-button-out">&lt;</button>
            <img id="gif-display-out" src="outpainting-1.gif" />
            <button id="right-button-out">&gt;</button>
        </div>
        <script src="script.js"></script> -->
        <div style="width: 100%;">
            <img class="image" style="width: 50%; float: left;"  src="outpainting-1.gif">
            <img class="image" style="width: 50%; float: right;" src="outpainting-2.gif">
        </div>
        <div style="width: 100%;">
            <img class="image" style="width: 50%; float: left;"  src="outpainting-3.gif">
            <img class="image" style="width: 50%; float: right;" src="outpainting-4.gif">
        </div>
        <div style="width: 100%;">
            <img class="image" style="width: 50%; float: left;"  src="outpainting-5.gif">
            <img class="image" style="width: 50%; float: right;" src="outpainting-6.gif">
        </div>
      </div>
      <div class="block">
        <p class="section-title">Abstract</p>
        <p class="paragraph">Recent advancements in diffusion-based generative image editing have sparked a profound revolution,
            reshaping the landscape of image outpainting and inpainting tasks. Despite these strides, the field grapples with inherent challenges,
            including: i) inferior quality; ii) poor consistency; iii) insufficient instrcution adherence; iv) suboptimal generation efficiency.
            To address these obstacles, we present <i><b>ByteEdit</b></i>, an innovative feedback learning framework meticulously designed
            to <b>B</b>oost, Compl<b>y</b>, and Accelera<b>te</b> Generative Image <b>Edit</b>ing tasks.
            ByteEdit seamlessly integrates image reward models dedicated to enhancing aesthetics and image-text alignment, while also introducing a
            dense, pixel-level reward model tailored to foster coherence in the output. Furthermore, we propose a pioneering adversarial and progressive
            feedback learning strategy to expedite the model's inference speed. Through extensive large-scale user evaluations, we demonstrate that
            ByteEdit surpasses leading generative image editing products, including Adobe, Canva, and MeiTu, in both generation quality and consistency.
            ByteEdit-Outpainting exhibits a remarkable enhancement of <b>388%</b> and <b>135%</b> in quality and consistency, respectively,
            when compared to the baseline model. Experiments also verfied that our acceleration models maintains excellent performance results
            in terms of quality and consistency.</p>
      </div>
      <div class="block">
        <p class="section-title" style="margin-top: 30px;">Examples</p>
        <div id="edit-examples">
        </div>
      </div>
      <div class="block">
        <p class="section-title" style="margin-top: 30px;">Pipeline</p>
        <p class="paragraph">
            ByteEdit formulates a comprehensive feedback learning framework that facilitating aesthetics, image-text matching, consistency and inference speed.
        </p>
        <img class="image" width="100%" src="images/pipeline.png">
      </div>
      <div class="block">
        <p class="section-title" style="margin-top: 30px;">Human Evaluation</p>
        <p class="paragraph">
            <!-- Comparisons with state-of-the-art generative image editing systems in terms of human preference (i.e. GSB).
            More than 12,000 samples are collected for each task.
            For simplicity and to minimize the difficulty of collecting a large number of user opinions, we only offer the generated images by Adobe and our ByteEdit to the volunteers.
            ``Good'' indicates the generated images by our ByteEdit is preferred and vice versa. -->
            To further investigate the gap between Adobe and our proposed ByteEdit, we solicited feedback from a large number of volunteers on the images generated by both, and the results are illustrated in the figure below.
            More than 12,000 samples are collected for each task.
            "Good" indicates the generated images by our ByteEdit is preferred and vice versa.
            The results show that users generally found the images we generated to be more natural in overall perception.
            Our GSB superiority percentages (i.e. (G+S)/(S+B) * 100%) on three different tasks are 105%, 163%, and 112%, respectively.
        </p>
        <img class="image" width="100%" src="images/preference-1.png">
        <p class="paragraph">
            Human Perference Evaluation on our proposed PeFL and Acceleration.
            Our proposed PeFL significantly improves the generation quality, outperforming the baseline on all different tasks.
            Especially in the outpainting task with PeFL, our method exceeds the baseline by about 60% in terms of structure and aesthetic.
            Moreover, our model has no significant loss in either consistency or structure and aesthetic with the progressive training strategy.
            To our surprise, we have even achieved both increasing speed and quality in the outpainting and inpainting-editing tasks.
        </p>
        <div style="width: 100%;">
            <img class="image" style="width: 50%; float: left;"  src="images/rlhf-1.png">
            <img class="image" style="width: 50%; float: right;" src="images/accelerate-1.png">
      </div>
    </div>
    <div class="block">
        <p class="section-title" style="margin-top: 30px;">BibTex</p>
        <div class="bibtex-container">
        <pre>
    @misc{ren2024byteedit,
        title={ByteEdit: Boost, Comply and Accelerate Generative Image Editing},
        author={Yuxi Ren and Jie Wu and Yanzuo Lu and Huafeng Kuang and Xin Xia and Xionghui Wang and Qianqian Wang and Yixing Zhu and Pan Xie and Shiyin Wang and Xuefeng Xiao and Yitong Wang and Min Zheng and Lean Fu},
        year={2024},
        eprint={2404.04860},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
    }
        </pre>
        </div>
    <div class="block"></div>
      </div>
    </div>
    </div>
  </body>
  <script type="text/javascript">

    const shortSwitchTime = 2000;
    const longSwitchTime = 6000;
    const imageIds = ["elephant", "coffee"];
    const images = {
      "elephant":
         {
           id: "elephant",
           src: "images/elephant/origin.png",
           currentlySelected: 0,
           nextSwitch: undefined,
           prompts: [
             '"across river"',
             '"flower surround"',
             '"ice and snow"',
             '"muddy trail"',
             '"rainforest"',
             '"the sea"'
           ],
           targets: [
             "images/elephant/elephant_1.png",
             "images/elephant/elephant_2.png",
             "images/elephant/elephant_3.png",
             "images/elephant/elephant_4.png",
             "images/elephant/elephant_5.png",
             "images/elephant/elephant_6.png"
           ]
         },
       "coffee":
         {
           id: "coffee",
           src: "images/coffee/origin.png",
           currentlySelected: 0,
           nextSwitch: undefined,
           prompts: [
             '"a coffee cup"',
             '"a cup of tea"',
             '"a pot"',
             '"coffee flavored cake"',
             "no prompt"
           ],
           targets: [
           "images/coffee/coffee_1.png",
             "images/coffee/coffee_2.png",
             "images/coffee/coffee_3.png",
             "images/coffee/coffee_4.png",
             "images/coffee/coffee_5.png",
           ]
         },
      }

    function switchImage(id, i){
      document.getElementById(`${id}-target-image`).src = images[id].targets[i];
      document.getElementById(`${id}-prompt-${images[id].currentlySelected}`).classList.remove('selected');
      document.getElementById(`${id}-prompt-${i}`).classList.add('selected');
      images[id].currentlySelected = i;
    }

    function newEditingBlock(imageId) {
      const editingBlock = document.createElement('div');
      editingBlock.classList.add('editing-block');

      const srcImage = document.createElement('img');
      srcImage.classList.add('image');
      srcImage.src = images[imageId].src;
      editingBlock.appendChild(srcImage);

      const prompts = document.createElement('div');
      prompts.classList.add('prompts');

      for (let i=0; i<images[imageId]["prompts"].length; ++i) {
        const prompt = document.createElement('p');
        prompt.innerText = images[imageId]["prompts"][i];
        prompt.classList.add('prompt');
        prompt.id = `${imageId}-prompt-${i}`;
        if (i == images[imageId].currentlySelected) {
          prompt.classList.add('selected');
        }
        prompt.onclick = () => {
          switchImage(imageId, i);
          images[imageId].nextSwitch = Date.now() + longSwitchTime;
        };
        prompts.appendChild(prompt);
      }

      editingBlock.appendChild(prompts);

      const targetImage = document.createElement('img');
      targetImage.classList.add('image');
      targetImage.id = `${imageId}-target-image`;
      targetImage.src = images[imageId].targets[0];
      editingBlock.appendChild(targetImage);

      document.getElementById('edit-examples').appendChild(editingBlock);
      images[imageId].nextSwitch = Date.now() + shortSwitchTime;
    }

    function loopThroughPrompts(imageId) {
      function moveToNextImage(imageId){
        const position = images[imageId].currentlySelected;
        const nextPosition = (position == images[imageId].prompts.length - 1) ? 0 : position + 1;
        switchImage(imageId, nextPosition);
      }

      if (Date.now() > images[imageId].nextSwitch) {
        images[imageId].nextSwitch = Date.now() + shortSwitchTime;
        moveToNextImage(imageId);
        loopThroughPrompts(imageId);
      } else {
        setTimeout(() => {
          loopThroughPrompts(imageId)
        }, 50);
      }
    }

    for (imageId of imageIds) {
      newEditingBlock(imageId);
      loopThroughPrompts(imageId);
    }
  </script>
</html>


